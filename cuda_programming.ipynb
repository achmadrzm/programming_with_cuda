{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdpb4J300Sym",
        "outputId": "9d46d885-e384-4733-ab07-f6e4e5c50d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "%pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phfuBhm11rXa",
        "outputId": "fff2c34f-a652-4422-b730-4f1c0f737d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpft70cx48\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 10000000\n",
        "\n",
        "// CUDA kernel to find max in an array\n",
        "__global__ void findMaxGPU(int *arr, int *max, int size) {\n",
        "    extern __shared__ int sdata[];\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;                            // mengakses elemen di memori global\n",
        "    int index = threadIdx.x;                                                    // mengakses elemen di memori shared\n",
        "\n",
        "    // Validasi thread\n",
        "    if (tid < size) {                                                           // Thread valid, salin data ke shared memory\n",
        "        sdata[index] = arr[tid];\n",
        "    } else {                                                                    // Thread tidak valid, isi dengan nilai INT_MIN\n",
        "        sdata[index] = INT_MIN;\n",
        "    }\n",
        "    __syncthreads();                                                            //semua thread yang ada dalam satu blok selesai menulis ke shared memory sebelum ada thread yang melanjutkan ke baris kode berikutnya.\n",
        "\n",
        "    //Mencari nilai max dengan cara memecah-mecah dan saling membandingkan antar thread\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "        if (index < s && sdata[index] < sdata[index + s]) {\n",
        "            sdata[index] = sdata[index + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    //Membandingkan nilai max antar block\n",
        "    if (index == 0) {\n",
        "        atomicMax(max, sdata[0]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Host function to find max on CPU\n",
        "int findMaxCPU(int *arr, int size) {\n",
        "    int max_val = arr[0];\n",
        "    for (int i = 1; i < size; i++) {\n",
        "        if (arr[i] > max_val) {\n",
        "            max_val = arr[i];\n",
        "        }\n",
        "    }\n",
        "    return max_val;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    srand(42);\n",
        "\n",
        "    int *h_arr = (int *)malloc(N * sizeof(int));                                // Mengalokasikan memori\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_arr[i] = rand() % 1000;                                               // Random values between 0 and 999\n",
        "    }\n",
        "\n",
        "    int h_max_cpu = findMaxCPU(h_arr, N);\n",
        "\n",
        "    int *d_arr, *d_max;\n",
        "    cudaMalloc((void **)&d_arr, N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_max, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_arr, h_arr, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemset(d_max, INT_MIN, sizeof(int));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "    // Start timing for GPU\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    findMaxGPU<<<gridSize, blockSize, blockSize * sizeof(int)>>>(d_arr, d_max, N);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    int h_max_gpu;\n",
        "    cudaMemcpy(&h_max_gpu, d_max, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Calculate GPU computation time\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    // CPU computation time\n",
        "    clock_t cpu_start = clock();\n",
        "    h_max_cpu = findMaxCPU(h_arr, N);\n",
        "    clock_t cpu_end = clock();\n",
        "    float cpu_time = 1000.0 * (cpu_end - cpu_start) / CLOCKS_PER_SEC;\n",
        "\n",
        "    // Display results\n",
        "    std::cout << \"Hasil di CPU: \" << h_max_cpu << std::endl;\n",
        "    std::cout << \"Hasil di GPU: \" << h_max_gpu << std::endl;\n",
        "    std::cout << \"Waktu komputasi:\" << std::endl;\n",
        "    std::cout << \"GPU Time: \" << milliseconds << \" ms\" << std::endl;\n",
        "    std::cout << \"CPU Time: \" << cpu_time << \" ms\" << std::endl;\n",
        "    std::cout << \"Speedup: \" << cpu_time / milliseconds << \"x\" << std::endl;\n",
        "\n",
        "    // Clean up\n",
        "    cudaFree(d_arr);\n",
        "    cudaFree(d_max);\n",
        "    free(h_arr);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4blEadu3RyI",
        "outputId": "0f855bf3-24b9-4877-a978-449968623b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil di CPU: 999\n",
            "Hasil di GPU: 999\n",
            "Waktu komputasi:\n",
            "GPU Time: 0.926176 ms\n",
            "CPU Time: 25.519 ms\n",
            "Speedup: 27.5531x\n",
            "\n"
          ]
        }
      ]
    }
  ]
}